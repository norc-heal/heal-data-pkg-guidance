{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Homepage of documentation \u00b6 This is a template for HEAL styled documentation. Good resources for developing documentaiton include: Materials mkdocs","title":"Home"},{"location":"#homepage-of-documentation","text":"This is a template for HEAL styled documentation. Good resources for developing documentaiton include: Materials mkdocs","title":"Homepage of documentation"},{"location":"section1/","text":"Section 1 \u00b6 This is the first section","title":"Section 1"},{"location":"section1/#section-1","text":"This is the first section","title":"Section 1"},{"location":"annot/","text":"Different annotation approaches \u00b6 After you determine your data sharing orientation, you must determine how you will annotate your data. Specifically, you must determine whether you want to annotate all files included in your study, regardless of whether they will shared (wholistic annotation), or whether you will annotate only those files that are necessary to reproduce your results or dataset of interest (minimal annotation). Whether you annotate 'as you go' or retrospectively ('top-down') will largely be dictated by where you are in your study when you start to think about data sharing and annotation. There are three main ways to annotate: Wholistic, As you go annotation: Annotating all study files as they are created, regardless of whether they will be shared Wholistic, Top-down annotation: Starting with your result or dataset of interest and working backwards, annotating all study files necessary to reproduce the result, regardless of whether they will shared Minimal, Top down annotation : Starting with your result or dataset of interest and working backwards, annotating only study files necessary to reproduce the result that will be shared","title":"Annotation Approaches"},{"location":"annot/#different-annotation-approaches","text":"After you determine your data sharing orientation, you must determine how you will annotate your data. Specifically, you must determine whether you want to annotate all files included in your study, regardless of whether they will shared (wholistic annotation), or whether you will annotate only those files that are necessary to reproduce your results or dataset of interest (minimal annotation). Whether you annotate 'as you go' or retrospectively ('top-down') will largely be dictated by where you are in your study when you start to think about data sharing and annotation. There are three main ways to annotate: Wholistic, As you go annotation: Annotating all study files as they are created, regardless of whether they will be shared Wholistic, Top-down annotation: Starting with your result or dataset of interest and working backwards, annotating all study files necessary to reproduce the result, regardless of whether they will shared Minimal, Top down annotation : Starting with your result or dataset of interest and working backwards, annotating only study files necessary to reproduce the result that will be shared","title":"Different annotation approaches"},{"location":"annot/introaddtop/","text":"As-you-go annotation of study artefacts \u00b6 This form of annotation involves tracking and annotating study data and non-data/supporting files as you move through the study. This type of annotation works best when paired with wholistic annotation . As-you-go annotation is built into the study process and so does not require dedicating a significant time at study end to retrospectively gather files and annotate. If you are fairly early in your study and have collected minimal or no data, \u2018as-you-go\u2019 annotation is recommended. Top-down annotation of study artefacts \u00b6 This form of annotation involves tracking and annotating study data and non-data/supporting files at the end of your study, retrospectively. This type of annotation works best when paired with minimal annotation , however top-down annotation can also be wholistic . The decision of wholistic vs. minimal annotation may be determined by the amount of time and resources your study has set aside for data sharing, as wholistic annotation would be more time consuming in a top-down orientation. If you are later in your study and have collected almost all or all of your data, \u2018top-down\u2019 annotation is recommended.","title":"As you go vs. Top-down"},{"location":"annot/introaddtop/#as-you-go-annotation-of-study-artefacts","text":"This form of annotation involves tracking and annotating study data and non-data/supporting files as you move through the study. This type of annotation works best when paired with wholistic annotation . As-you-go annotation is built into the study process and so does not require dedicating a significant time at study end to retrospectively gather files and annotate. If you are fairly early in your study and have collected minimal or no data, \u2018as-you-go\u2019 annotation is recommended.","title":"As-you-go annotation of study artefacts"},{"location":"annot/introaddtop/#top-down-annotation-of-study-artefacts","text":"This form of annotation involves tracking and annotating study data and non-data/supporting files at the end of your study, retrospectively. This type of annotation works best when paired with minimal annotation , however top-down annotation can also be wholistic . The decision of wholistic vs. minimal annotation may be determined by the amount of time and resources your study has set aside for data sharing, as wholistic annotation would be more time consuming in a top-down orientation. If you are later in your study and have collected almost all or all of your data, \u2018top-down\u2019 annotation is recommended.","title":"Top-down annotation of study artefacts"},{"location":"annot/introholmin/","text":"Wholistic annotation of study artefacts \u00b6 Wholistic annotation involves creating and maintaining documentation that catalogues and annotates all files and non-data/supporting documents generated by and associated with your study regardless of whether you are planning to share them. Files that will not be shared are documented as permanent-private. This type of annotation works best paired with 'as you go' annotation , as it easier an less time consuming to annotate wholistically, retrospectively, as part of 'top-down' annotation . Although this mode of annotation is more time consuming, it maximizes transparency and allows investigators interested in the data to understand the full scope of the project when accessing study documentation on the Platform. This structure also allows for documentation of the existence and disposition of files that are too sensitive to share but are important for reproducibility and can perhaps be requested directly from the study team by an investigator. Who may choose to share this way Study groups that have not started collecting data or are very early in the data collection process. Study groups that are earlier in the process and are interested in understanding and implementing a file and folder structure that facilitates data sharing in the future. Study groups that want to maximise the amount of information that they share about their study. Pros to sharing this way You get the benefit of full local annotation, which not only maximizes the usefulness of your data for other investigators but also can be helpful internally, especially in preserving knowledge about the data even as team members may change over the course of the study. Although more time consuming at the beginning, integration of this process into your workflows allows for documentation and annotation in parts as you move through the study, so that you do not need to compile all that information at the end of the study, retrospectively. Documenting and sharing all metadata associated with your study can increase the discoverability of your study. Cons to sharing this way More time consuming, because it requires you to set up the structures to fully catalogue all data and non-data/supporting files that are relevant to your study. Notes about wholistic annotation If you are early in your study and choose to pursue wholistic annotation, we recommend you consider reviewing and implementing [HEAL recommendations for organizing and naming of study artefacts]. This will ease the process of annotation as well as future data sharing. If you are annotating wholistically, you will also document dependencies 'one-layer-deep'. For more information, see Resource Tracker: Associated Files/Dependencies and 'One Layer Deep' Dependencies . Minimal annotation of study artefacts \u00b6 Minimal annotation starts with the main file you are focused on sharing, whether that is a multi-result file, such as a publication or presentation, or a dataset, and works backwards. Rather than documenting all files, you document only the data and non-data file dependencies required to reproduce the final results or dataset. This is likely more ideal for studies that may be close to data collection completion and are not focused on meeting data sharing requirements but do not have adequate funding or time to devote the complete documentation of the data. This type of annotation pairs well with \u2018top-down\u2019 annotation , which retrospectively annotates study artefacts. Who may choose to share this way Study groups that may be finished or close to finished collecting data and have already produced results files (e.g., figures, draft publications/NIH reports, etc.) Study groups that want to meet minimal data sharing requirements of sharing data underlying published results Pros to sharing this way You only catalog the data and non-data/supporting files that you will share/submit to a repository. This is less work than fully cataloguing all data and non-data/supporting files relevant to a study (including files you will not share/submit to a repository), especially if the study is well underway or complete/nearing completion and/or does not have resources or time set aside for a complete file inventory. This approach allows you to fulfill the minimal data sharing requirements of sharing data underlying published results. Cons to sharing this way You don\u2019t get the full local annotation benefit that would come with fully cataloguing all data and non-data/supporting files relevant to a study (including files you will not share/submit to a repository), and how they relate to each other and to published results \u2013 these benefits include facilitating continuity and passed-down knowledge within study groups , and discovery, sharing, and re-use of the data and knowledge produced by the study outside of the original study group. You don\u2019t get the full benefit of the added discoverability that data-package level metadata can provide. Notes about minimal annotation Even if you are not early in your study and are pursuing minimal annotation, we do not recommend reorganizing all your files or folder structures. However, we do recommend you consider reviewing and implementing naming conventions for like files, detailed in [HEAL recommendations for organizing and naming study artefacts]. This will ease the process of annotation. If you are annotating minimally, you will document dependences 'liberally'. For more information, see [Resource Tracker: Associated Files/Dependencies] adn ['Liberal' Dependencies].","title":"Wholistic vs. Minimal"},{"location":"annot/introholmin/#wholistic-annotation-of-study-artefacts","text":"Wholistic annotation involves creating and maintaining documentation that catalogues and annotates all files and non-data/supporting documents generated by and associated with your study regardless of whether you are planning to share them. Files that will not be shared are documented as permanent-private. This type of annotation works best paired with 'as you go' annotation , as it easier an less time consuming to annotate wholistically, retrospectively, as part of 'top-down' annotation . Although this mode of annotation is more time consuming, it maximizes transparency and allows investigators interested in the data to understand the full scope of the project when accessing study documentation on the Platform. This structure also allows for documentation of the existence and disposition of files that are too sensitive to share but are important for reproducibility and can perhaps be requested directly from the study team by an investigator. Who may choose to share this way Study groups that have not started collecting data or are very early in the data collection process. Study groups that are earlier in the process and are interested in understanding and implementing a file and folder structure that facilitates data sharing in the future. Study groups that want to maximise the amount of information that they share about their study. Pros to sharing this way You get the benefit of full local annotation, which not only maximizes the usefulness of your data for other investigators but also can be helpful internally, especially in preserving knowledge about the data even as team members may change over the course of the study. Although more time consuming at the beginning, integration of this process into your workflows allows for documentation and annotation in parts as you move through the study, so that you do not need to compile all that information at the end of the study, retrospectively. Documenting and sharing all metadata associated with your study can increase the discoverability of your study. Cons to sharing this way More time consuming, because it requires you to set up the structures to fully catalogue all data and non-data/supporting files that are relevant to your study. Notes about wholistic annotation If you are early in your study and choose to pursue wholistic annotation, we recommend you consider reviewing and implementing [HEAL recommendations for organizing and naming of study artefacts]. This will ease the process of annotation as well as future data sharing. If you are annotating wholistically, you will also document dependencies 'one-layer-deep'. For more information, see Resource Tracker: Associated Files/Dependencies and 'One Layer Deep' Dependencies .","title":"Wholistic annotation of study artefacts"},{"location":"annot/introholmin/#minimal-annotation-of-study-artefacts","text":"Minimal annotation starts with the main file you are focused on sharing, whether that is a multi-result file, such as a publication or presentation, or a dataset, and works backwards. Rather than documenting all files, you document only the data and non-data file dependencies required to reproduce the final results or dataset. This is likely more ideal for studies that may be close to data collection completion and are not focused on meeting data sharing requirements but do not have adequate funding or time to devote the complete documentation of the data. This type of annotation pairs well with \u2018top-down\u2019 annotation , which retrospectively annotates study artefacts. Who may choose to share this way Study groups that may be finished or close to finished collecting data and have already produced results files (e.g., figures, draft publications/NIH reports, etc.) Study groups that want to meet minimal data sharing requirements of sharing data underlying published results Pros to sharing this way You only catalog the data and non-data/supporting files that you will share/submit to a repository. This is less work than fully cataloguing all data and non-data/supporting files relevant to a study (including files you will not share/submit to a repository), especially if the study is well underway or complete/nearing completion and/or does not have resources or time set aside for a complete file inventory. This approach allows you to fulfill the minimal data sharing requirements of sharing data underlying published results. Cons to sharing this way You don\u2019t get the full local annotation benefit that would come with fully cataloguing all data and non-data/supporting files relevant to a study (including files you will not share/submit to a repository), and how they relate to each other and to published results \u2013 these benefits include facilitating continuity and passed-down knowledge within study groups , and discovery, sharing, and re-use of the data and knowledge produced by the study outside of the original study group. You don\u2019t get the full benefit of the added discoverability that data-package level metadata can provide. Notes about minimal annotation Even if you are not early in your study and are pursuing minimal annotation, we do not recommend reorganizing all your files or folder structures. However, we do recommend you consider reviewing and implementing naming conventions for like files, detailed in [HEAL recommendations for organizing and naming study artefacts]. This will ease the process of annotation. If you are annotating minimally, you will document dependences 'liberally'. For more information, see [Resource Tracker: Associated Files/Dependencies] adn ['Liberal' Dependencies].","title":"Minimal annotation of study artefacts"},{"location":"guide/","text":"When deciding how you will share and annotate your study data, you should consider two key questions . What is your orientation towards data sharing? How far along are you in your study? 1. What is your orientation towards data sharing? \u00b6 Determining what your goals are for data sharing will help guide you in determining what you will include in your future data package and how you will annotate the data and non-data/supporting documents in your dat package. People will have different goals in sharing their study data, which can be dictated by a number of factors such as the nature of the data, resources and time constraints, and investigator preference. There are two main \"data sharing orientations.\" They are not mutually exclusive. See more about each data sharing orientation below. Results-support This orientation is for investigators who are interested only in fulfilling the requirement to share the data that is necessary to reproduce their results. Example Your study is complete, and you have very limited time or resources budgeted for data sharing. You have published a manuscript on your results or are in the process of submitting one. You want to fulfill the minimum data sharing requirements, so you will only share the data required to reproduce the manuscript results. Dataset-oriented This orientation is for investigators who are interested in sharing a specific set of data or as much data as possible so that other researchers can get additional value from them, such as conducting additional research and analyes beyond the original study's focus. Example Your study is collecting RNA expression data. You are only focusing on a small subset of the collected data for your study, but you would like to be able to share as much of this data as possible so that other investigators can comb through the rich data for other analyses and insight. 2. How far along are you in your study? \u00b6 Where you are in your study when you start to think about data sharing will affect how you document your data. For example, if you are near the beginning of your study, you may be able to set up documentation processes such that you document as you move through your study, which will ease the process of data sharing in the future, as opposed to completing all documentation at the end. If you are early in your study and/or have collected little data and non-data/supporting elements, click here . If you are later in your study and/or have collected a large amount of data and non-data/supporting elements, click here .","title":"Main Guiding Questions"},{"location":"guide/#1-what-is-your-orientation-towards-data-sharing","text":"Determining what your goals are for data sharing will help guide you in determining what you will include in your future data package and how you will annotate the data and non-data/supporting documents in your dat package. People will have different goals in sharing their study data, which can be dictated by a number of factors such as the nature of the data, resources and time constraints, and investigator preference. There are two main \"data sharing orientations.\" They are not mutually exclusive. See more about each data sharing orientation below. Results-support This orientation is for investigators who are interested only in fulfilling the requirement to share the data that is necessary to reproduce their results. Example Your study is complete, and you have very limited time or resources budgeted for data sharing. You have published a manuscript on your results or are in the process of submitting one. You want to fulfill the minimum data sharing requirements, so you will only share the data required to reproduce the manuscript results. Dataset-oriented This orientation is for investigators who are interested in sharing a specific set of data or as much data as possible so that other researchers can get additional value from them, such as conducting additional research and analyes beyond the original study's focus. Example Your study is collecting RNA expression data. You are only focusing on a small subset of the collected data for your study, but you would like to be able to share as much of this data as possible so that other investigators can comb through the rich data for other analyses and insight.","title":"1. What is your orientation towards data sharing?"},{"location":"guide/#2-how-far-along-are-you-in-your-study","text":"Where you are in your study when you start to think about data sharing will affect how you document your data. For example, if you are near the beginning of your study, you may be able to set up documentation processes such that you document as you move through your study, which will ease the process of data sharing in the future, as opposed to completing all documentation at the end. If you are early in your study and/or have collected little data and non-data/supporting elements, click here . If you are later in your study and/or have collected a large amount of data and non-data/supporting elements, click here .","title":"2. How far along are you in your study?"},{"location":"guide/early/","text":"EARLY in study \u00b6 Use Wholistic As-You-Go Annotation Consider implementing HEAL recommendations for organization and naming of study artefacts (Note: Do not copy/duplicate files to implement) Consider annotating all study files as they are created, starting right away ( 'as you go' annotation ), regardless of whether they will be shared ( 'wholistic' annotation ) of study artefacts to reduce annotation burden at the end of the study Recommendations differ depending on your data-sharing orientation: Dataset-oriented Results-support Annotate up to and including your shareable dataset Annotate up to and including your published/shared multi-result file(s) Include and annotate a results-tracker for each multi-result file","title":"Early in study"},{"location":"guide/early/#early-in-study","text":"Use Wholistic As-You-Go Annotation Consider implementing HEAL recommendations for organization and naming of study artefacts (Note: Do not copy/duplicate files to implement) Consider annotating all study files as they are created, starting right away ( 'as you go' annotation ), regardless of whether they will be shared ( 'wholistic' annotation ) of study artefacts to reduce annotation burden at the end of the study Recommendations differ depending on your data-sharing orientation: Dataset-oriented Results-support Annotate up to and including your shareable dataset Annotate up to and including your published/shared multi-result file(s) Include and annotate a results-tracker for each multi-result file","title":"EARLY in study"},{"location":"guide/late/","text":"LATE in study \u00b6 Use Wholistic OR Minimal Top-Down Annotation The way you annotate will vary based on your data-sharing orientation: \u00b6 Dataset-oriented Results-support If you are interested in sharing a specific dataset and documenting the necessary pieces to reproduce that dataset, recommended steps include: Wait until shareable dataset(s) are produced Annotate shareable dataset(s) in the resource tracker Annotate dependencies of shareable dataset(s) (e.g., data dictionary, protocol, raw data, code) Annotate dependencies of those dependencies, continuing with this cycle until final dependencies you annotate have no dependencies of their own See below for information on how to document dependencies If you are interested in sharing data and support files that support a specific result, recommended steps include: Wait until the multi-result file(s) are produced Annotate multi-result file(s) Create a results tracker for each multi-result file. Within the results tracker, list each result and its dependencies (e.g., data, data dictionary, code, statistical analysis plan) Annotate results tracker(s) Annotate dependencies of results as listed in the results tracker(s) Annotate dependencies of those dependencies, continuing with this cycle until final dependencies you annotate have no dependencies of their own See below for information on how to document dependencies Document the results tracker(s) as an entry into the resource tracker Regardless of your data-sharing orientation, the way you document dependencies will vary based on your annotation approach: \u00b6 Wholistic Minimal List dependencies 'one-layer-deep', regardless of whether those dependencies will be shared Annotate all dependencies regardless of whether they will be shared. List dependencies 'liberally', regardless of whether those dependencies will be shared Annotate only dependencies that will be shared. If your data sharing orientation is dataset-oriented ... \u00b6 If you are interested in sharing a specific dataset and documenting the necessary pieces to reproduce that dataset, recommended steps include: Wait until shareable dataset(s) are produced Annotate shareable dataset(s) in the resource tracker Annotate dependencies of shareable dataset(s) (e.g., data dictionary, protocol, raw data, code) Annotate dependencies of those dependencies, continuing with this cycle until final dependencies you annotate have no dependencies of their own The way you annotate dependencies will vary based on your annotation approach: Wholistic Minimal List dependencies 'one-layer-deep', regardless of whether those dependencies will be shared Annotate all dependencies regardless of whether they will be shared. List dependencies 'liberally', regardless of whether those dependencies will be shared Annotate only dependencies that will be shared. If your data sharing orientation is results-support ... \u00b6 If you are interested in sharing data and support files that support a specific result, recommended steps include: Wait until the multi-result file(s) are produced Annotate multi-result file(s) Create a results tracker for each multi-result file. Within the results tracker, list each result and its dependencies (e.g., data, data dictionary, code, statistical analysis plan) Annotate results tracker(s) Annotate dependencies of results as listed in the results tracker(s) Annotate dependencies of those dependencies, continuing with this cycle until final dependencies you annotate have no dependencies of their own Document the results tracker(s) as an entry into the resource tracker The way you annotate dependencies will vary based on your annotation approach: Wholistic Minimal List dependencies 'one-layer-deep', regardless of whether those dependencies will be shared Annotate all dependencies regardless of whether they will be shared. List dependencies 'liberally', regardless of whether those dependencies will be shared Annotate only dependencies that will be shared.","title":"Late in study"},{"location":"guide/late/#late-in-study","text":"Use Wholistic OR Minimal Top-Down Annotation","title":"LATE in study"},{"location":"guide/late/#the-way-you-annotate-will-vary-based-on-your-data-sharing-orientation","text":"Dataset-oriented Results-support If you are interested in sharing a specific dataset and documenting the necessary pieces to reproduce that dataset, recommended steps include: Wait until shareable dataset(s) are produced Annotate shareable dataset(s) in the resource tracker Annotate dependencies of shareable dataset(s) (e.g., data dictionary, protocol, raw data, code) Annotate dependencies of those dependencies, continuing with this cycle until final dependencies you annotate have no dependencies of their own See below for information on how to document dependencies If you are interested in sharing data and support files that support a specific result, recommended steps include: Wait until the multi-result file(s) are produced Annotate multi-result file(s) Create a results tracker for each multi-result file. Within the results tracker, list each result and its dependencies (e.g., data, data dictionary, code, statistical analysis plan) Annotate results tracker(s) Annotate dependencies of results as listed in the results tracker(s) Annotate dependencies of those dependencies, continuing with this cycle until final dependencies you annotate have no dependencies of their own See below for information on how to document dependencies Document the results tracker(s) as an entry into the resource tracker","title":"The way you annotate will vary based on your data-sharing orientation:"},{"location":"guide/late/#regardless-of-your-data-sharing-orientation-the-way-you-document-dependencies-will-vary-based-on-your-annotation-approach","text":"Wholistic Minimal List dependencies 'one-layer-deep', regardless of whether those dependencies will be shared Annotate all dependencies regardless of whether they will be shared. List dependencies 'liberally', regardless of whether those dependencies will be shared Annotate only dependencies that will be shared.","title":"Regardless of your data-sharing orientation, the way you document dependencies will vary based on your annotation approach:"},{"location":"guide/late/#if-your-data-sharing-orientation-is-dataset-oriented","text":"If you are interested in sharing a specific dataset and documenting the necessary pieces to reproduce that dataset, recommended steps include: Wait until shareable dataset(s) are produced Annotate shareable dataset(s) in the resource tracker Annotate dependencies of shareable dataset(s) (e.g., data dictionary, protocol, raw data, code) Annotate dependencies of those dependencies, continuing with this cycle until final dependencies you annotate have no dependencies of their own The way you annotate dependencies will vary based on your annotation approach: Wholistic Minimal List dependencies 'one-layer-deep', regardless of whether those dependencies will be shared Annotate all dependencies regardless of whether they will be shared. List dependencies 'liberally', regardless of whether those dependencies will be shared Annotate only dependencies that will be shared.","title":"If your data sharing orientation is dataset-oriented..."},{"location":"guide/late/#if-your-data-sharing-orientation-is-results-support","text":"If you are interested in sharing data and support files that support a specific result, recommended steps include: Wait until the multi-result file(s) are produced Annotate multi-result file(s) Create a results tracker for each multi-result file. Within the results tracker, list each result and its dependencies (e.g., data, data dictionary, code, statistical analysis plan) Annotate results tracker(s) Annotate dependencies of results as listed in the results tracker(s) Annotate dependencies of those dependencies, continuing with this cycle until final dependencies you annotate have no dependencies of their own Document the results tracker(s) as an entry into the resource tracker The way you annotate dependencies will vary based on your annotation approach: Wholistic Minimal List dependencies 'one-layer-deep', regardless of whether those dependencies will be shared Annotate all dependencies regardless of whether they will be shared. List dependencies 'liberally', regardless of whether those dependencies will be shared Annotate only dependencies that will be shared.","title":"If your data sharing orientation is results-support..."},{"location":"intro/","text":"Home page for Section 2 \u00b6 Overview \u00b6 Home page for section 2","title":"Home page for Section 2"},{"location":"intro/#home-page-for-section-2","text":"","title":"Home page for Section 2"},{"location":"intro/#overview","text":"Home page for section 2","title":"Overview"},{"location":"intro/flmd/","text":"If your study produces tabular data Timing : Start on this right away; no need to take the Decision Tree Quiz ahead of time Create one data dictionary for every tabular data file If your study has a 'results-support' data sharing orientation Timing : Take Decision Tree Quiz first; note recommendations from quiz regarding whether and how your study should implement the results tracker Create one results tracker for every multi-result file that requires support","title":"Flmd"},{"location":"intro/resource/","text":"About the Resource Tracker \u00b6 The resource tracker is an inventory and annotated list of all data and supporting/non-date files for the study. Purpose \u00b6 Guides interpretation, use, and replication Gives information on all/shared study artefacts, what items are shared, where/how to find them, how to understand/interpret those items</li Documents who different items relate to each other and how they relate to the dataset and/or result the study group will share. This is useful for potential secondary data users as well as the original study group, which may need to reference/replicate past experiments/results across people and time. Preparation for submission to a repository Can allow reconfiguration of file organization for sharing both in location and tiem based on the type of itme (e.g., data, metadata, code), access level (permanent private, temporary private, restricted access, public), date of access level change (e.g., shared access date) When submitting to a reposiotry with robust API infrastructure, can allow for automated submission with interpretable organization, respecting all access settings How your study should implement the resource tracker will depend on three dimensions: \u00b6 Stage of accumulation of study artefacts (study stage) Have already accumulated many study artefacts, OR Have accumulated relatively few or no study artefacts Data sharing 'orientation' (goal) Focused on sharing items that support your published results, AND/OR Focused on sharing a useful dataset Annotation plan Documenting all study artefacts related to your data sharing goal(s), OR Documenting only study artefacts related to your data sharing goal that will be shared in a public repository For guidance on answering these key questions, click here. \u00b6","title":"The Resource Tracker"},{"location":"intro/resource/#about-the-resource-tracker","text":"The resource tracker is an inventory and annotated list of all data and supporting/non-date files for the study.","title":"About the Resource Tracker"},{"location":"intro/resource/#purpose","text":"Guides interpretation, use, and replication Gives information on all/shared study artefacts, what items are shared, where/how to find them, how to understand/interpret those items</li Documents who different items relate to each other and how they relate to the dataset and/or result the study group will share. This is useful for potential secondary data users as well as the original study group, which may need to reference/replicate past experiments/results across people and time. Preparation for submission to a repository Can allow reconfiguration of file organization for sharing both in location and tiem based on the type of itme (e.g., data, metadata, code), access level (permanent private, temporary private, restricted access, public), date of access level change (e.g., shared access date) When submitting to a reposiotry with robust API infrastructure, can allow for automated submission with interpretable organization, respecting all access settings","title":"Purpose"},{"location":"intro/resource/#how-your-study-should-implement-the-resource-tracker-will-depend-on-three-dimensions","text":"Stage of accumulation of study artefacts (study stage) Have already accumulated many study artefacts, OR Have accumulated relatively few or no study artefacts Data sharing 'orientation' (goal) Focused on sharing items that support your published results, AND/OR Focused on sharing a useful dataset Annotation plan Documenting all study artefacts related to your data sharing goal(s), OR Documenting only study artefacts related to your data sharing goal that will be shared in a public repository","title":"How your study should implement the resource tracker will depend on three dimensions:"},{"location":"intro/resource/#for-guidance-on-answering-these-key-questions-click-here","text":"","title":"For guidance on answering these key questions, click here."},{"location":"intro/slmd/","text":"Every study should create one experiment tracker Timing : Start on this right away; no need to take the Decision Tree Quiz ahead of time Content : Lists all experiments/activities in the study, including high-level description, experimental questions, and hypotheses Purpose : Gives a high-level overview of what the study was trying to ask/answer and how it went about answering that (more detailed than SLMD) Every study should create one resource tracker Timing : Take Decision Tree Quiz first; note recommendations from quiz regarding how your study should implement the resource tracker Content : Lists all/shared study artefacts and dependencies Purpose : Interpreting, using, replicating : Gives information on all/shared study artefacts, what items are shared, where/how to find it, how to understand/interpret it, how to use it, how different teams relate to each other, how different items relate to the dataset and/or results the study group will share (useful for potential secondary data users and originating study group which may need to reference/replicate past experiments/results across people and time) Submitting to a repository : Can allow reconfiguration of file organization for sharing both in location and time based on type of item (e.g., data, metadata, code), access level (permanent private, temporary private, restricted access, public), date of access level change (e.g., shared access date) - when submitting to a repository with robust API infrastructure, can allow for automated submission with interpretable organization and respecting all access settings How your study should implement the resource tracker will depend on at least three dimensions: Stage of accumulation of study artefacts : Have already accumulated many study artefacts OR have accumulated relatively few study artefacts Low accumulation : Add-as-you-go annotation High accumulation : Top-down annotation Data sharing 'orientation' (goal) : Focused on sharing items that support your published results AND/OR focused on sharing a useful dataset Results support : Top-down annotation, starting with multi-result files (e.g., pubs) Dataset : Low accumulation : Add-as-you-go annotation, ending with final dataset(s) High accumulation : Top-down annotation, starting with final dataset(s) Wholistic versus minimal : Lists all study artefacts related to your data sharing goal(s) OR only study artefacts that are related to your data sharing goal(s) AND will be shared in a public repository Results support : Top-down annotation, starting with multi-result files (e.g., pubs) Wholistic annotation : More work but more useful to potential secondary data users and to originating study group members Minimal annotation : Still incredibly useful to potentail secondary data users; minimizes work Dataset : Low accumulation : Add-as-you-go, wholistic annotation, ending with final dataset(s) High accumulation : Top-down annotation, starting with final dataset(s) Wholistic annotation : More work but more useful to potential secondary data users and to originating study group members Minimal annotation : Still incredibly useful to potential secondary data users; minimizes work","title":"Slmd"},{"location":"section3/","text":"Are you early in collection/production of study artefacts? \u00b6 Yes No Early In Study \u00b6 Consider implementing HEAL recommendations for organization and naming of study artefacts (Note: Do not copy/duplicate files to implement) Consider wholistic annotation of study artefacts (annotate all study artefacts) Consider 'add as you go' annotation of study artefacts to reduce annotation burden at the end of the study If you are not interested wholistically annotating your study as you go, click here . Late In Study \u00b6 Choose the response which best represents your study's situation. The number of total study artefacts is relatively small OR Your study group is particularly interested in implementing high levels of transparency to increase understandability and continuity of data knowledge internally or externally? The number of total study artefacts is relatively large OR Your study group is more interested in implementing only mandated levels of transparency sufficient to provide context about the study and data Small number of study artefacts or interested in high levels of transparency in data sharing \u00b6 Consider implementing HEAL recommendations for organization and naming of study artefacts. Consider wholistic annotation of study artefacts (annotate all study artefacts). If you have not completed collecting/producing all study artefacts, consider annotating all artefacts already collected, then proceed with 'add as you' annotation of new study artefacts to reduce annotation burden at the end of the study. If you have complete collecting/producing all study artefacts, use 'top down' annotation. If you are not interested in this approach, click here . Large number of study artefacts or interested in implementing mandated levels of transparency \u00b6 Leave your original organization and naming of study artefacts in place. Exception If your study collected relatively large sets of 'like' files (e.g., a tabular file pre study subject per day with several measurements that have the same format across files) and these files do not have a consistent naming convention, we recommend implementing a consistent file name convention to increase interpretability/usability to potential secondary data users and make annotation of these files much simpler and faster\" Consider minimal annotation of study artefacts (annotate only study artefacts that will be shared) to reduce annotation burden while providing helpful context for potential secondary data users. Consider 'top down' annotation of study artefacts based on your data sharing 'orientation' goal(s) to minimize annotation to a set that directly serves your data sharing goals. What is your data sharing 'orientation'? \u00b6 Which of these best describes your orientation towards data sharing. You may be interested in more than one of these, in which case, you may want to review the recommendations for both (if they are different). Interested in sharing a dataset that other investigators could use to gain new insights Interested in sharing only the data that supports my results (a publication, presentation, etc.) Interested in sharing the methods underlying my data so other investigators can apply or build upon them","title":"Are you early in collection/production of study artefacts?"},{"location":"section3/#are-you-early-in-collectionproduction-of-study-artefacts","text":"Yes No","title":"Are you early in collection/production of study artefacts?"},{"location":"section3/#early-in-study","text":"Consider implementing HEAL recommendations for organization and naming of study artefacts (Note: Do not copy/duplicate files to implement) Consider wholistic annotation of study artefacts (annotate all study artefacts) Consider 'add as you go' annotation of study artefacts to reduce annotation burden at the end of the study If you are not interested wholistically annotating your study as you go, click here .","title":"Early In Study"},{"location":"section3/#late-in-study","text":"Choose the response which best represents your study's situation. The number of total study artefacts is relatively small OR Your study group is particularly interested in implementing high levels of transparency to increase understandability and continuity of data knowledge internally or externally? The number of total study artefacts is relatively large OR Your study group is more interested in implementing only mandated levels of transparency sufficient to provide context about the study and data","title":"Late In Study"},{"location":"section3/#small-number-of-study-artefacts-or-interested-in-high-levels-of-transparency-in-data-sharing","text":"Consider implementing HEAL recommendations for organization and naming of study artefacts. Consider wholistic annotation of study artefacts (annotate all study artefacts). If you have not completed collecting/producing all study artefacts, consider annotating all artefacts already collected, then proceed with 'add as you' annotation of new study artefacts to reduce annotation burden at the end of the study. If you have complete collecting/producing all study artefacts, use 'top down' annotation. If you are not interested in this approach, click here .","title":"Small number of study artefacts or interested in high levels of transparency in data sharing"},{"location":"section3/#large-number-of-study-artefacts-or-interested-in-implementing-mandated-levels-of-transparency","text":"Leave your original organization and naming of study artefacts in place. Exception If your study collected relatively large sets of 'like' files (e.g., a tabular file pre study subject per day with several measurements that have the same format across files) and these files do not have a consistent naming convention, we recommend implementing a consistent file name convention to increase interpretability/usability to potential secondary data users and make annotation of these files much simpler and faster\" Consider minimal annotation of study artefacts (annotate only study artefacts that will be shared) to reduce annotation burden while providing helpful context for potential secondary data users. Consider 'top down' annotation of study artefacts based on your data sharing 'orientation' goal(s) to minimize annotation to a set that directly serves your data sharing goals.","title":"Large number of study artefacts or interested in implementing mandated levels of transparency"},{"location":"section3/#what-is-your-data-sharing-orientation","text":"Which of these best describes your orientation towards data sharing. You may be interested in more than one of these, in which case, you may want to review the recommendations for both (if they are different). Interested in sharing a dataset that other investigators could use to gain new insights Interested in sharing only the data that supports my results (a publication, presentation, etc.) Interested in sharing the methods underlying my data so other investigators can apply or build upon them","title":"What is your data sharing 'orientation'?"},{"location":"section3/dec/","text":"Are you early in collection/production of study artefacts? \u00b6 Yes No","title":"Are you early in collection/production of study artefacts?"},{"location":"section3/dec/#are-you-early-in-collectionproduction-of-study-artefacts","text":"Yes No","title":"Are you early in collection/production of study artefacts?"},{"location":"section3/dec/early/","text":"Early In Study \u00b6 Consider implementing HEAL recommendations for organization and naming of study artefacts (Note: Do not copy/duplicate files to implement) Consider wholistic annotation of study artefacts (annotate all study artefacts) Consider 'add as you go' annotation of study artefacts to reduce annotation burden at the end of the study If you are not interested wholistically annotating your study as you go, click here .","title":"Early In Study"},{"location":"section3/dec/early/#early-in-study","text":"Consider implementing HEAL recommendations for organization and naming of study artefacts (Note: Do not copy/duplicate files to implement) Consider wholistic annotation of study artefacts (annotate all study artefacts) Consider 'add as you go' annotation of study artefacts to reduce annotation burden at the end of the study If you are not interested wholistically annotating your study as you go, click here .","title":"Early In Study"},{"location":"section3/dec/late/","text":"Late In Study \u00b6 Choose the response which best represents your study's situation. The number of total study artefacts is relatively small OR Your study group is particularly interested in implementing high levels of transparency to increase understandability and continuity of data knowledge internally or externally The number of total study artefacts is relatively large OR Your study group is more interested in implementing only mandated levels of transparency sufficient to provide context about the study and data","title":"Late In Study"},{"location":"section3/dec/late/#late-in-study","text":"Choose the response which best represents your study's situation. The number of total study artefacts is relatively small OR Your study group is particularly interested in implementing high levels of transparency to increase understandability and continuity of data knowledge internally or externally The number of total study artefacts is relatively large OR Your study group is more interested in implementing only mandated levels of transparency sufficient to provide context about the study and data","title":"Late In Study"},{"location":"section3/dec/late/large/","text":"Leave your original organization and naming of study artefacts in place. Exception If your study collected relatively large sets of 'like' files (e.g., a tabular file pre study subject per day with several measurements that have the same format across files) and these files do not have a consistent naming convention, we recommend implementing a consistent file name convention to increase interpretability/usability to potential secondary data users and make annotation of these files much simpler and faster\" Consider minimal annotation of study artefacts (annotate only study artefacts that will be shared) to reduce annotation burden while providing helpful context for potential secondary data users. Consider 'top down' annotation of study artefacts based on your data sharing 'orientation' goal(s) to minimize annotation to a set that directly serves your data sharing goals.","title":"Large"},{"location":"section3/dec/late/small/","text":"Consider implementing HEAL recommendations for organization and naming of study artefacts . Consider wholistic annotation of study artefacts (annotate all study artefacts). If you have not completed collecting/producing all study artefacts, consider annotating all artefacts already collected, then proceed with ['add as you' go annotation] of new study artefacts to reduce annotation burden at the end of the study. If you have complete collecting/producing all study artefacts, use ['top down' annotation]. If you are not interested in this approach, click here .","title":"Small"},{"location":"section3/orient/orient/","text":"Determining what your goals are for data sharing will help guide you in determing what you will include in your future data package and how you will annotate the data and non-data/supporting documents in your data package. People will have different goals in sharing their study data, which can be dictated by a number of factors such as the nature of the data, resource and time constraints, and investigator preference. There are three main orientations. You do not have to pick just one of these orientations, although results-support is more likely to stand alone. For example, investigators may be interested in sharing a specific dataset in addition to data on their materials and methods. See more about each data sharing orientation below. Results-support This orientation is for investigators who are interested only in fulfilling the requirement to share the data that is necessary to reproduce their results. Example Your study is complete, and you have very limited time or resources budgeted for data sharing. You have published a manuscript on your results or are in the process of submitting one. You want to fulfill the minimum data sharing requirements, so you will only share the data required to reproduce the manuscript results. If this best describes your data sharing orientation, click [here](resultsupp.md). Dataset-oriented This orientation is for investigators who are interested in sharing a specific set of data or as much data as possible so that other researchers can get additional value from them, such as conducting additional research and analyes beyond the original study's focus. Example Your study is collecting RNA expression data. You are only focusing on a small subset of the collected data for your study, but you would like to be able to share as much of this data as possible so that other investigators can comb through the rich data for other analyses and insight. If this best describes your data sharing orientation, click here. Materials- and methods-oriented This orientation is for investigators who are inteersted in sharing inforamtion about their materials and methods that would allow others to reproduce or build upon them in future research. Example Your study is building an organ-on-a-chip model. You want to share information about the formulation of the chip and results demonstrating that the chip performs similarly as the organ in vivo, so that other investigators can understand the process and reassemble and build upon your successful model in future research. If this best describes your data sharing orientation, click here.","title":"Orient"},{"location":"section3/orient/resultsupp/","text":"If you are planning to share only files that are necessary to support the results in a multi-result file, such as a manuscript or presentation: Use 'top-down' annotation. Do not use 'add-as-you-go' annotation. Audit multi-result file(s) that need support Audit supporting files for each result in multi-result file(s), including sharing status and access level Audit dependencies of supporting files, including sharing status and access level Add data dictionary for any tabular supporting files or dependencies Create result tracker for each multi-result file (list supporting files for each result in the result tracker 'depends on' field). To determine what approach you should take to listing supporting files for each result, click here . Add result tracker to resource tracker Add supporting files to resource tracker (list dependencies for each supporting resource tracker 'depends on' field) Notes on wholistic vs. minimal annotation If using wholistic annotation : When adding supporting files for results in the results tracker, add 'one-layer-deep' dependencies . When adding dependencies of supporting files in the resource tracker, add 'one-layer-deep' dependencies . If using minimal annotation When adding supporting files for results in the results tracker, add 'liberal' dependencies . When adding dependencies of supporting files in the resource tracker, add 'liberal' dependencies .","title":"Resultsupp"},{"location":"terms/","text":"Tabular data file \u00b6 A data file that is organized in a table with rows and columns. Multi-result file \u00b6 A file that contains multiple results from your study. Some examples of multi-results files include manuscripts, posters, and presentations. Multi-result files and the results tracker For each multi-result file associated with your study, you should create a corresponding results tracker. For more information on the results tracker, [click here]. Study artefacts \u00b6 All files and non-data/supporting documents generated by and associated with your study, regardless of whether you are planning to share them. Study-level Metadata: Experiment Tracker \u00b6 The experiment tracker provides contextual information on the experimetns that are involved in the study. Each row of the experiment tracker corresponds to one experiment. Information about the experiment includes research questions(s), approach, and hypotheses. For detailed information on the name and definition of each field in the experiment tracker, please refer to the [experiment tracker schema]. Study-level Metadata: Resource Tracker \u00b6 The resource tracker is an inventory and annotate list of all data and supporting/non-date files for the study. Each row of the resource tracker corresponds to one data or non-data resource. Informaiton in the tracker about each resource includes file path, description, access restrictions, format, corresponding software, and dependencies. The resource tracker is where you will also list and annotate any associated any associated results trackers docummenting multi-result files. See [Resource Tracker: Associated Files/Dependencies] for more information on how you should document your dependencies, depending on the type and amount of data you are sharing. For detailed information on the name and definition of each field in the resource tracker, please refer to the [resource tracker schema]. File-level Metadata: Data Dictionary \u00b6 File-level Metadata: Results Tracker \u00b6 The results tracker provides detailed information and annotation for multi-result files (e.g., manuscript, presentation). Each multi-result file will have a corresponding results tracker. The purpose of this tracker is to track and annotate each single result (e.g., a figure or textual statement) within each multiresult file as well as all the data and supporting files upon which each single result depends. Within the results tracker, each row corresponds to one result from the multi-result file. Information about each result includes type of result (figure or text), description, and supported claims. Note Each results tracker should be additionally listed and annotated as its own row in the resource tracker. For detailed information on the name and defiition of each field in the results tracker, please refer to the [results tracker schema]. Wholistic annotation of study artefacts \u00b6 Wholistic annotation involves creating and maintaining documentation that catalogues and annotates all files and non-data/supporting documents generated by and associated with your study regardless of whether you are planning to share them. Files that will not be shared are documented as permanent-private. This type of annotation works best paired with ['add as you go' annotation], as it easier an less time consuming to annotate wholistically, retrospectively, as part of ['top-down' annotation]. Although this mode of annotation is more time consuming, it maximizes transparency and allows investigators interested in the data to understand the full scope of the project when accessing study documentation on the Platform. This structure also allows for documentation of the existence and disposition of files that are too sensitive to share but are important for reproducibility and can perhaps be requested directly from the study team by an investigator. Who may choose to share this way Study groups that have not started collecting data or are very early in the data collection process. Study groups that are earlier in the process and are interested in understanding and implementing a file and folder structure that facilitates data sharing in the future. Study groups that want to maximise the amount of information that they share about their study. Pros to sharing this way You get the benefit of full local annotation, which not only maximizes the usefulness of your data for other investigators but also can be helpful internally, especially in preserving knowledge about the data even as team members may change over the course of the study. Although more time consuming at the beginning, integration of this process into your workflows allows for documentation and annotation in parts as you move through the study, so that you do not need to compile all that information at the end of the study, retrospectively. Documenting and sharing all metadata associated with your study can increase the discoverability of your study. Cons to sharing this way More time consuming, because it requires you to set up the structures to fully catalogue all data and non-data/supporting files that are relevant to your study. Notes about wholistic annotation If you are early in your study and choose to pursue wholistic annotation, we recommend you consider reviewing and implementing [HEAL recommendations for organizing and naming of study artefacts]. This will ease the process of annotation as well as future data sharing. If you are annotating wholistically, you will also document dependencies 'one-layer-deep'. For more information, see [Resource Tracker: Associated Files/Dependencies] and ['One Layer Deep' Dependencies]. Minimal annotation of study artefacts \u00b6 Minimal annotation starts with the main file you are focused on sharing, whether that is a multi-result file, such as a publication or presentation, or a dataset, and works backwards. Rather than documenting all files, you document only the data and non-data file dependencies required to reproduce the final results or dataset. This is likely more ideal for studies that may be close to data collection completion and are not focused on meeting data sharing requirements but do not have adequate funding or time to devote the complete documentation of the data. This type of annotation pairs well with \u2018top-down\u2019 annotation, which retrospectively annotates study artefacts. Who may choose to share this way Study groups that may be finished or close to finished collecting data and have already produced results files (e.g., figures, draft publications/NIH reports, etc.) Study groups that want to meet minimal data sharing requirements of sharing data underlying published results Pros to sharing this way You only catalog the data and non-data/supporting files that you will share/submit to a repository. This is less work than fully cataloguing all data and non-data/supporting files relevant to a study (including files you will not share/submit to a repository), especially if the study is well underway or complete/nearing completion and/or does not have resources or time set aside for a complete file inventory. This approach allows you to fulfill the minimal data sharing requirements of sharing data underlying published results. Cons to sharing this way You don\u2019t get the full local annotation benefit that would come with fully cataloguing all data and non-data/supporting files relevant to a study (including files you will not share/submit to a repository), and how they relate to each other and to published results \u2013 these benefits include facilitating continuity and passed-down knowledge within study groups , and discovery, sharing, and re-use of the data and knowledge produced by the study outside of the original study group. You don\u2019t get the full benefit of the added discoverability that data-package level metadata can provide. Notes about minimal annotation Even if you are not early in your study and are pursuing minimal annotation, we do not recommend reorganizing all your files or folder structures. However, we do recommend you consider reviewing and implementing naming conventions for like files, detailed in [HEAL recommendations for organizing and naming study artefacts]. This will ease the process of annotation. If you are annotating minimally, you will document dependences 'liberally'. For more information, see [Resource Tracker: Associated Files/Dependencies] adn ['Liberal' Dependencies].","title":"Terms & Concepts"},{"location":"terms/#tabular-data-file","text":"A data file that is organized in a table with rows and columns.","title":"Tabular data file"},{"location":"terms/#multi-result-file","text":"A file that contains multiple results from your study. Some examples of multi-results files include manuscripts, posters, and presentations. Multi-result files and the results tracker For each multi-result file associated with your study, you should create a corresponding results tracker. For more information on the results tracker, [click here].","title":"Multi-result file"},{"location":"terms/#study-artefacts","text":"All files and non-data/supporting documents generated by and associated with your study, regardless of whether you are planning to share them.","title":"Study artefacts"},{"location":"terms/#study-level-metadata-experiment-tracker","text":"The experiment tracker provides contextual information on the experimetns that are involved in the study. Each row of the experiment tracker corresponds to one experiment. Information about the experiment includes research questions(s), approach, and hypotheses. For detailed information on the name and definition of each field in the experiment tracker, please refer to the [experiment tracker schema].","title":"Study-level Metadata: Experiment Tracker"},{"location":"terms/#study-level-metadata-resource-tracker","text":"The resource tracker is an inventory and annotate list of all data and supporting/non-date files for the study. Each row of the resource tracker corresponds to one data or non-data resource. Informaiton in the tracker about each resource includes file path, description, access restrictions, format, corresponding software, and dependencies. The resource tracker is where you will also list and annotate any associated any associated results trackers docummenting multi-result files. See [Resource Tracker: Associated Files/Dependencies] for more information on how you should document your dependencies, depending on the type and amount of data you are sharing. For detailed information on the name and definition of each field in the resource tracker, please refer to the [resource tracker schema].","title":"Study-level Metadata: Resource Tracker"},{"location":"terms/#file-level-metadata-data-dictionary","text":"","title":"File-level Metadata: Data Dictionary"},{"location":"terms/#file-level-metadata-results-tracker","text":"The results tracker provides detailed information and annotation for multi-result files (e.g., manuscript, presentation). Each multi-result file will have a corresponding results tracker. The purpose of this tracker is to track and annotate each single result (e.g., a figure or textual statement) within each multiresult file as well as all the data and supporting files upon which each single result depends. Within the results tracker, each row corresponds to one result from the multi-result file. Information about each result includes type of result (figure or text), description, and supported claims. Note Each results tracker should be additionally listed and annotated as its own row in the resource tracker. For detailed information on the name and defiition of each field in the results tracker, please refer to the [results tracker schema].","title":"File-level Metadata: Results Tracker"},{"location":"terms/#wholistic-annotation-of-study-artefacts","text":"Wholistic annotation involves creating and maintaining documentation that catalogues and annotates all files and non-data/supporting documents generated by and associated with your study regardless of whether you are planning to share them. Files that will not be shared are documented as permanent-private. This type of annotation works best paired with ['add as you go' annotation], as it easier an less time consuming to annotate wholistically, retrospectively, as part of ['top-down' annotation]. Although this mode of annotation is more time consuming, it maximizes transparency and allows investigators interested in the data to understand the full scope of the project when accessing study documentation on the Platform. This structure also allows for documentation of the existence and disposition of files that are too sensitive to share but are important for reproducibility and can perhaps be requested directly from the study team by an investigator. Who may choose to share this way Study groups that have not started collecting data or are very early in the data collection process. Study groups that are earlier in the process and are interested in understanding and implementing a file and folder structure that facilitates data sharing in the future. Study groups that want to maximise the amount of information that they share about their study. Pros to sharing this way You get the benefit of full local annotation, which not only maximizes the usefulness of your data for other investigators but also can be helpful internally, especially in preserving knowledge about the data even as team members may change over the course of the study. Although more time consuming at the beginning, integration of this process into your workflows allows for documentation and annotation in parts as you move through the study, so that you do not need to compile all that information at the end of the study, retrospectively. Documenting and sharing all metadata associated with your study can increase the discoverability of your study. Cons to sharing this way More time consuming, because it requires you to set up the structures to fully catalogue all data and non-data/supporting files that are relevant to your study. Notes about wholistic annotation If you are early in your study and choose to pursue wholistic annotation, we recommend you consider reviewing and implementing [HEAL recommendations for organizing and naming of study artefacts]. This will ease the process of annotation as well as future data sharing. If you are annotating wholistically, you will also document dependencies 'one-layer-deep'. For more information, see [Resource Tracker: Associated Files/Dependencies] and ['One Layer Deep' Dependencies].","title":"Wholistic annotation of study artefacts"},{"location":"terms/#minimal-annotation-of-study-artefacts","text":"Minimal annotation starts with the main file you are focused on sharing, whether that is a multi-result file, such as a publication or presentation, or a dataset, and works backwards. Rather than documenting all files, you document only the data and non-data file dependencies required to reproduce the final results or dataset. This is likely more ideal for studies that may be close to data collection completion and are not focused on meeting data sharing requirements but do not have adequate funding or time to devote the complete documentation of the data. This type of annotation pairs well with \u2018top-down\u2019 annotation, which retrospectively annotates study artefacts. Who may choose to share this way Study groups that may be finished or close to finished collecting data and have already produced results files (e.g., figures, draft publications/NIH reports, etc.) Study groups that want to meet minimal data sharing requirements of sharing data underlying published results Pros to sharing this way You only catalog the data and non-data/supporting files that you will share/submit to a repository. This is less work than fully cataloguing all data and non-data/supporting files relevant to a study (including files you will not share/submit to a repository), especially if the study is well underway or complete/nearing completion and/or does not have resources or time set aside for a complete file inventory. This approach allows you to fulfill the minimal data sharing requirements of sharing data underlying published results. Cons to sharing this way You don\u2019t get the full local annotation benefit that would come with fully cataloguing all data and non-data/supporting files relevant to a study (including files you will not share/submit to a repository), and how they relate to each other and to published results \u2013 these benefits include facilitating continuity and passed-down knowledge within study groups , and discovery, sharing, and re-use of the data and knowledge produced by the study outside of the original study group. You don\u2019t get the full benefit of the added discoverability that data-package level metadata can provide. Notes about minimal annotation Even if you are not early in your study and are pursuing minimal annotation, we do not recommend reorganizing all your files or folder structures. However, we do recommend you consider reviewing and implementing naming conventions for like files, detailed in [HEAL recommendations for organizing and naming study artefacts]. This will ease the process of annotation. If you are annotating minimally, you will document dependences 'liberally'. For more information, see [Resource Tracker: Associated Files/Dependencies] adn ['Liberal' Dependencies].","title":"Minimal annotation of study artefacts"},{"location":"terms/addtop/","text":"Add-as-you-go annotation of study artefacts \u00b6 This form of annotation involves tracking and annotating study data and non-data/supporting files as you move through the study. This type of annotation works best when paired with wholistic annotation . Add-as-you-go annotation is built into the study process and so does not require dedicating a significant time at study end to retrospectively gather files and annotate. If you are fairly early in your study and have collected minimal or no data, \u2018add-as-you-go\u2019 annotation is recommended. Top-down annotation of study artefacts \u00b6 This form of annotation involves tracking and annotating study data and non-data/supporting files at the end of your study, retrospectively. This type of annotation works best when paired with minimal annotation , however top-down annotation can also be wholistic . The decision of wholistic vs. minimal annotation may be determined by the amount of time and resources your study has set aside for data sharing, as wholistic annotation would be more time consuming in a top-down orientation. If you are later in your study and have collected almost all or all of your data, \u2018top-down\u2019 annotation is recommended.","title":"Add-as-you-go vs. Top-down Annotation"},{"location":"terms/addtop/#add-as-you-go-annotation-of-study-artefacts","text":"This form of annotation involves tracking and annotating study data and non-data/supporting files as you move through the study. This type of annotation works best when paired with wholistic annotation . Add-as-you-go annotation is built into the study process and so does not require dedicating a significant time at study end to retrospectively gather files and annotate. If you are fairly early in your study and have collected minimal or no data, \u2018add-as-you-go\u2019 annotation is recommended.","title":"Add-as-you-go annotation of study artefacts"},{"location":"terms/addtop/#top-down-annotation-of-study-artefacts","text":"This form of annotation involves tracking and annotating study data and non-data/supporting files at the end of your study, retrospectively. This type of annotation works best when paired with minimal annotation , however top-down annotation can also be wholistic . The decision of wholistic vs. minimal annotation may be determined by the amount of time and resources your study has set aside for data sharing, as wholistic annotation would be more time consuming in a top-down orientation. If you are later in your study and have collected almost all or all of your data, \u2018top-down\u2019 annotation is recommended.","title":"Top-down annotation of study artefacts"},{"location":"terms/depend/","text":"'One Layer Deep' Dependencies \u00b6 Annotation using 'one-layer-deep' dependencies means only documenting the immediate dependencies needed to produce/interpret/use the artefact. If you are using wholistic annotation, you will use the 'one-layer-deep' approach while documenting dependencies. Each row/entry of the resource tracker will only have one dependency (the immediate file/document needed to create the file). The next row will list that dependency and document its dependencies, and so on, until you are annotating files with not dependencies. Given that wholistic annotation inolves documenting all files, this will allow researchers to trace the order of dependencies in a cascade to the original source files. THis will ease the ability to understand and reproduce results. 'Liberal' Dependencies \u00b6 Annotation using \u2018liberal\u2019 dependencies means documenting all dependencies, immediate and distal, needed to produce/interpret/use each artefact. If you are using minimal annotation, you will use the \u2018liberal\u2019 approach when documenting dependencies. Each row/entry of the resource tracker will include immediate dependencies (as in the \u2018one-layer-deep\u2019 approach) as well as the dependencies of those dependencies. Given that minimal annotation means that you are not documenting all study artefacts, this will allow researchers to understand the cascade of dependencies involved in producing each artefact, even if not all dependencies are entries in the resource tracker.","title":"Documenting dependencies"},{"location":"terms/depend/#one-layer-deep-dependencies","text":"Annotation using 'one-layer-deep' dependencies means only documenting the immediate dependencies needed to produce/interpret/use the artefact. If you are using wholistic annotation, you will use the 'one-layer-deep' approach while documenting dependencies. Each row/entry of the resource tracker will only have one dependency (the immediate file/document needed to create the file). The next row will list that dependency and document its dependencies, and so on, until you are annotating files with not dependencies. Given that wholistic annotation inolves documenting all files, this will allow researchers to trace the order of dependencies in a cascade to the original source files. THis will ease the ability to understand and reproduce results.","title":"'One Layer Deep' Dependencies"},{"location":"terms/depend/#liberal-dependencies","text":"Annotation using \u2018liberal\u2019 dependencies means documenting all dependencies, immediate and distal, needed to produce/interpret/use each artefact. If you are using minimal annotation, you will use the \u2018liberal\u2019 approach when documenting dependencies. Each row/entry of the resource tracker will include immediate dependencies (as in the \u2018one-layer-deep\u2019 approach) as well as the dependencies of those dependencies. Given that minimal annotation means that you are not documenting all study artefacts, this will allow researchers to understand the cascade of dependencies involved in producing each artefact, even if not all dependencies are entries in the resource tracker.","title":"'Liberal' Dependencies"},{"location":"terms/filelevel/","text":"Results Tracker \u00b6 The results tracker provider detailed information and annotation for multi-result files (e.g., manuscript, presentation). Each multi-result file will have a corresponding results tracker. The purpose of this tracker is to track and annotate each single result (e.g., a figure or textual statement) within each multi-result file as well as the data and supporting files upone which each single result depends. Within the result tracker, each row corresponds to one result from the multi-result file. Information eabout each result includes type of result (figure or text), description, and supported claims. Each results tracker should additionally be listed and annotated as its own row in the resource tracker . For detailed information on the name and definition of each field in the results tracker, please refer to the [LINK: results tracker schema]. Associated Files/Dependencies \u00b6 Any file that the study artefact being annotated depends on to be produced, interpreted, or used (e.g. a processed tabular data file may depend on a raw data file(s), plus a code file that implements the statistical analysis plan to be produced, and require a data dictionary to interpret/use) How you annotate the dependencies of a file in the result tracker will depend on whether you are annotating wholistically or minimally. If you are annotating artefacts wholistically Use the 'one layer deep' approach : list only the immediate dependencies needed to produce/interpret/use the result. List each dependency in the result tracker in its own row/entry For each row, list dependencies of that file one layer deep Continue until you are annotating files with no dependencies If you are annotating artefacts minimally Use the 'liberal' approach : list all dependencies. For a result, list immediate dependencies needed to produce/interpret/use the artefact plus dependencies of those dependencies Continue until you are listing files with no dependencies mkdo Example \u00b6 A processed tabular data file may depend on a raw data file(s), plus a code file that implements the statistical analysis plan to be produced, and require a data dictionary to interpret/use. For more information on 'one layer deep' and 'liberal' dependency documentation, click here. 'One layer deep' Dependencies Liberal Dependencies Immediately underlying raw data files, plus a code file that implements the statistical analysis plan and 'transforms' the raw data files into the processed data file, plus the data dictionary for the processed data file All immediate/one layer deep files, AND The statistical analysis plan that was used to produce the code, the data dictionary for the raw underlying data file(s), a protocol for collection of the raw underlying data file(s), etc. If possible, list liberal dependencies in order from most immediate to least immediate. Data Dictionary \u00b6 Each tabular data file should have its own data dictionary. The data dictionary describes the content, format, and structure of the data file. Within the data dictionary, each row contains information about each variable such as the name, description, type, format, and encodings. The data dictionary is a critical piece in re-use of the data by future researchers, as it contains information about how to read, format, and interpret the data. For detailed information on the name and definition of each field in the data dictionary, please refer to the [LINK: data dictionary schema]. Helpful tip If you are creating data dictionaries, save the data dictionary with the same filename as the data file, with a \"dd-\" prefix. Example: dd-my-data-1.csv","title":"File-level Metadata"},{"location":"terms/filelevel/#results-tracker","text":"The results tracker provider detailed information and annotation for multi-result files (e.g., manuscript, presentation). Each multi-result file will have a corresponding results tracker. The purpose of this tracker is to track and annotate each single result (e.g., a figure or textual statement) within each multi-result file as well as the data and supporting files upone which each single result depends. Within the result tracker, each row corresponds to one result from the multi-result file. Information eabout each result includes type of result (figure or text), description, and supported claims. Each results tracker should additionally be listed and annotated as its own row in the resource tracker . For detailed information on the name and definition of each field in the results tracker, please refer to the [LINK: results tracker schema].","title":"Results Tracker"},{"location":"terms/filelevel/#associated-filesdependencies","text":"Any file that the study artefact being annotated depends on to be produced, interpreted, or used (e.g. a processed tabular data file may depend on a raw data file(s), plus a code file that implements the statistical analysis plan to be produced, and require a data dictionary to interpret/use) How you annotate the dependencies of a file in the result tracker will depend on whether you are annotating wholistically or minimally. If you are annotating artefacts wholistically Use the 'one layer deep' approach : list only the immediate dependencies needed to produce/interpret/use the result. List each dependency in the result tracker in its own row/entry For each row, list dependencies of that file one layer deep Continue until you are annotating files with no dependencies If you are annotating artefacts minimally Use the 'liberal' approach : list all dependencies. For a result, list immediate dependencies needed to produce/interpret/use the artefact plus dependencies of those dependencies Continue until you are listing files with no dependencies mkdo","title":"Associated Files/Dependencies"},{"location":"terms/filelevel/#example","text":"A processed tabular data file may depend on a raw data file(s), plus a code file that implements the statistical analysis plan to be produced, and require a data dictionary to interpret/use. For more information on 'one layer deep' and 'liberal' dependency documentation, click here. 'One layer deep' Dependencies Liberal Dependencies Immediately underlying raw data files, plus a code file that implements the statistical analysis plan and 'transforms' the raw data files into the processed data file, plus the data dictionary for the processed data file All immediate/one layer deep files, AND The statistical analysis plan that was used to produce the code, the data dictionary for the raw underlying data file(s), a protocol for collection of the raw underlying data file(s), etc. If possible, list liberal dependencies in order from most immediate to least immediate.","title":"Example"},{"location":"terms/filelevel/#data-dictionary","text":"Each tabular data file should have its own data dictionary. The data dictionary describes the content, format, and structure of the data file. Within the data dictionary, each row contains information about each variable such as the name, description, type, format, and encodings. The data dictionary is a critical piece in re-use of the data by future researchers, as it contains information about how to read, format, and interpret the data. For detailed information on the name and definition of each field in the data dictionary, please refer to the [LINK: data dictionary schema]. Helpful tip If you are creating data dictionaries, save the data dictionary with the same filename as the data file, with a \"dd-\" prefix. Example: dd-my-data-1.csv","title":"Data Dictionary"},{"location":"terms/files/","text":"Tabular data file \u00b6 A data file that is organized in a table with rows and columns. Multi-result file \u00b6 A file that contains multiple results from your study. Some examples of multi-results files include manuscripts, posters, and presentations. Multi-result files and the results tracker For each multi-result file associated with your study, you should create a corresponding results tracker. For more information on the results tracker, [click here].","title":"File Types"},{"location":"terms/files/#tabular-data-file","text":"A data file that is organized in a table with rows and columns.","title":"Tabular data file"},{"location":"terms/files/#multi-result-file","text":"A file that contains multiple results from your study. Some examples of multi-results files include manuscripts, posters, and presentations. Multi-result files and the results tracker For each multi-result file associated with your study, you should create a corresponding results tracker. For more information on the results tracker, [click here].","title":"Multi-result file"},{"location":"terms/holmin/","text":"Wholistic annotation of study artefacts \u00b6 Wholistic annotation involves creating and maintaining documentation that catalogues and annotates all files and non-data/supporting documents generated by and associated with your study regardless of whether you are planning to share them. Files that will not be shared are documented as permanent-private. This type of annotation works best paired with ['add as you go' annotation], as it easier an less time consuming to annotate wholistically, retrospectively, as part of ['top-down' annotation]. Although this mode of annotation is more time consuming, it maximizes transparency and allows investigators interested in the data to understand the full scope of the project when accessing study documentation on the Platform. This structure also allows for documentation of the existence and disposition of files that are too sensitive to share but are important for reproducibility and can perhaps be requested directly from the study team by an investigator. Who may choose to share this way Study groups that have not started collecting data or are very early in the data collection process. Study groups that are earlier in the process and are interested in understanding and implementing a file and folder structure that facilitates data sharing in the future. Study groups that want to maximise the amount of information that they share about their study. Pros to sharing this way You get the benefit of full local annotation, which not only maximizes the usefulness of your data for other investigators but also can be helpful internally, especially in preserving knowledge about the data even as team members may change over the course of the study. Although more time consuming at the beginning, integration of this process into your workflows allows for documentation and annotation in parts as you move through the study, so that you do not need to compile all that information at the end of the study, retrospectively. Documenting and sharing all metadata associated with your study can increase the discoverability of your study. Cons to sharing this way More time consuming, because it requires you to set up the structures to fully catalogue all data and non-data/supporting files that are relevant to your study. Notes about wholistic annotation If you are early in your study and choose to pursue wholistic annotation, we recommend you consider reviewing and implementing [HEAL recommendations for organizing and naming of study artefacts]. This will ease the process of annotation as well as future data sharing. If you are annotating wholistically, you will also document dependencies 'one-layer-deep'. For more information, see [Resource Tracker: Associated Files/Dependencies] and ['One Layer Deep' Dependencies]. Minimal annotation of study artefacts \u00b6 Minimal annotation starts with the main file you are focused on sharing, whether that is a multi-result file, such as a publication or presentation, or a dataset, and works backwards. Rather than documenting all files, you document only the data and non-data file dependencies required to reproduce the final results or dataset. This is likely more ideal for studies that may be close to data collection completion and are not focused on meeting data sharing requirements but do not have adequate funding or time to devote the complete documentation of the data. This type of annotation pairs well with \u2018top-down\u2019 annotation, which retrospectively annotates study artefacts. Who may choose to share this way Study groups that may be finished or close to finished collecting data and have already produced results files (e.g., figures, draft publications/NIH reports, etc.) Study groups that want to meet minimal data sharing requirements of sharing data underlying published results Pros to sharing this way You only catalog the data and non-data/supporting files that you will share/submit to a repository. This is less work than fully cataloguing all data and non-data/supporting files relevant to a study (including files you will not share/submit to a repository), especially if the study is well underway or complete/nearing completion and/or does not have resources or time set aside for a complete file inventory. This approach allows you to fulfill the minimal data sharing requirements of sharing data underlying published results. Cons to sharing this way You don\u2019t get the full local annotation benefit that would come with fully cataloguing all data and non-data/supporting files relevant to a study (including files you will not share/submit to a repository), and how they relate to each other and to published results \u2013 these benefits include facilitating continuity and passed-down knowledge within study groups , and discovery, sharing, and re-use of the data and knowledge produced by the study outside of the original study group. You don\u2019t get the full benefit of the added discoverability that data-package level metadata can provide. Notes about minimal annotation Even if you are not early in your study and are pursuing minimal annotation, we do not recommend reorganizing all your files or folder structures. However, we do recommend you consider reviewing and implementing naming conventions for like files, detailed in [HEAL recommendations for organizing and naming study artefacts]. This will ease the process of annotation. If you are annotating minimally, you will document dependences 'liberally'. For more information, see [Resource Tracker: Associated Files/Dependencies] adn ['Liberal' Dependencies].","title":"Holistic vs. Minimal Annotation"},{"location":"terms/holmin/#wholistic-annotation-of-study-artefacts","text":"Wholistic annotation involves creating and maintaining documentation that catalogues and annotates all files and non-data/supporting documents generated by and associated with your study regardless of whether you are planning to share them. Files that will not be shared are documented as permanent-private. This type of annotation works best paired with ['add as you go' annotation], as it easier an less time consuming to annotate wholistically, retrospectively, as part of ['top-down' annotation]. Although this mode of annotation is more time consuming, it maximizes transparency and allows investigators interested in the data to understand the full scope of the project when accessing study documentation on the Platform. This structure also allows for documentation of the existence and disposition of files that are too sensitive to share but are important for reproducibility and can perhaps be requested directly from the study team by an investigator. Who may choose to share this way Study groups that have not started collecting data or are very early in the data collection process. Study groups that are earlier in the process and are interested in understanding and implementing a file and folder structure that facilitates data sharing in the future. Study groups that want to maximise the amount of information that they share about their study. Pros to sharing this way You get the benefit of full local annotation, which not only maximizes the usefulness of your data for other investigators but also can be helpful internally, especially in preserving knowledge about the data even as team members may change over the course of the study. Although more time consuming at the beginning, integration of this process into your workflows allows for documentation and annotation in parts as you move through the study, so that you do not need to compile all that information at the end of the study, retrospectively. Documenting and sharing all metadata associated with your study can increase the discoverability of your study. Cons to sharing this way More time consuming, because it requires you to set up the structures to fully catalogue all data and non-data/supporting files that are relevant to your study. Notes about wholistic annotation If you are early in your study and choose to pursue wholistic annotation, we recommend you consider reviewing and implementing [HEAL recommendations for organizing and naming of study artefacts]. This will ease the process of annotation as well as future data sharing. If you are annotating wholistically, you will also document dependencies 'one-layer-deep'. For more information, see [Resource Tracker: Associated Files/Dependencies] and ['One Layer Deep' Dependencies].","title":"Wholistic annotation of study artefacts"},{"location":"terms/holmin/#minimal-annotation-of-study-artefacts","text":"Minimal annotation starts with the main file you are focused on sharing, whether that is a multi-result file, such as a publication or presentation, or a dataset, and works backwards. Rather than documenting all files, you document only the data and non-data file dependencies required to reproduce the final results or dataset. This is likely more ideal for studies that may be close to data collection completion and are not focused on meeting data sharing requirements but do not have adequate funding or time to devote the complete documentation of the data. This type of annotation pairs well with \u2018top-down\u2019 annotation, which retrospectively annotates study artefacts. Who may choose to share this way Study groups that may be finished or close to finished collecting data and have already produced results files (e.g., figures, draft publications/NIH reports, etc.) Study groups that want to meet minimal data sharing requirements of sharing data underlying published results Pros to sharing this way You only catalog the data and non-data/supporting files that you will share/submit to a repository. This is less work than fully cataloguing all data and non-data/supporting files relevant to a study (including files you will not share/submit to a repository), especially if the study is well underway or complete/nearing completion and/or does not have resources or time set aside for a complete file inventory. This approach allows you to fulfill the minimal data sharing requirements of sharing data underlying published results. Cons to sharing this way You don\u2019t get the full local annotation benefit that would come with fully cataloguing all data and non-data/supporting files relevant to a study (including files you will not share/submit to a repository), and how they relate to each other and to published results \u2013 these benefits include facilitating continuity and passed-down knowledge within study groups , and discovery, sharing, and re-use of the data and knowledge produced by the study outside of the original study group. You don\u2019t get the full benefit of the added discoverability that data-package level metadata can provide. Notes about minimal annotation Even if you are not early in your study and are pursuing minimal annotation, we do not recommend reorganizing all your files or folder structures. However, we do recommend you consider reviewing and implementing naming conventions for like files, detailed in [HEAL recommendations for organizing and naming study artefacts]. This will ease the process of annotation. If you are annotating minimally, you will document dependences 'liberally'. For more information, see [Resource Tracker: Associated Files/Dependencies] adn ['Liberal' Dependencies].","title":"Minimal annotation of study artefacts"},{"location":"terms/name/","text":"Organize study-related files into folders with consistent naming conventions \u00b6 Organize all your files (whether you will share them or not), into folders. In general, minimize the number of folders at each level, and the number of 'layers' of your whole directory. File naming conventions can often be used quite effectively to 'organize' files and to provide clues as to what the files are and how they relate to each other without resorting to using separation into different directories to serve that purpose. However, there is a limit to naming conventions, and you may want to separate your files into directors based on some type of logical groupings and/or based on th elevel or timing of access to the files you expect to provide. See below for further details. Reminder Before creating more directories or directory layers, consider whether file-naming conventions may be used more efficiently to create this organization. Create logical groupings \u00b6 There are a number of ways to group files logically. Below are some examples of how you can logically group your files in folder structures: Grouping strategy Examples By file category Raw data grouped together; processed data grouped together; protocols grouped together; data dictionaries grouped together By experimental subject All raw data files from a particular cell (across all protocols grouped together, etc.) By type of experiment All current clamp experiment files grouped together; all voltage clamp experiment files grouped together By experiment All raw data files mkdocsfrom a particular protocol, across all cells to which the protocol applies, grouped together By file type All CorelDraw figure files grouped together By expected use All files you expect a primary or secondary user of the data/metadata would want to use and/or cite together (as a package) - for example, grouping files that you expect you will want to provide different levels of access to/access restrictions for and/or that you want to provide access to with different timing. See below for more information on access level and timing. Consistently name your files and folders \u00b6 Universal conventions \u00b6 File and folder names should generally be informative/descriptive Wherever possible name your files and folders in a way that will let a human user reasonably infer quite a lot about what the file holds without any further information It is very helpful if file and folder names are all lower case Don't use spaces or special characters Preferred separator is a dash ('-'), e.g., my-data-file-1 Special conventions \u00b6 If you have multiple files or folders of the same type , choose a naming convention that's descriptive, and not unmanageably long, and be consistent. For example: One file per day, per cell, per protocol: Potential convention: \"day\"-YYYY-MM-DD-\"cell\"-[0-9]-\"protocol\"-{short-protocol-description} Example filename: day-2023-03-17-cell-3-protocol-200ms-pulse.asc One folder per experimental objective: Potential convention: {cell-type}-{short-experimental-approach-description}-{short-experimental-objective-description} Example foldrer name: drg-current-clamp-effect-of-K1395R-on-drg-neuronal-excitability; drg-voltage-clamp-biophysical-properties-of-K1395R If you have files that are related , choose a naming convention that's descriptive, and not unmanageably long, and be consistent. For example: A tabular/csv data file that has a data dictionary Potential convention: The data dictionary for a data file has the same filename as the data file, with a \"dd-\" prefix Example file name(s): Data file name : my-data-1.csv Corresponding data dictionary file name : dd-my-data-1.csv Several experiments that each have an experimental protocol Potential convention: The protocol of the experiment has the id of that experiment (from the experiment tracker) in the filename, with a \"protocol-\" prefix Example file name(s): Experiment id (from experiment tracker) : exp-1 Corresponding protocol file name : protocol-exp-1.txt","title":"HEAL recommendations for organization and naming of study artefacts"},{"location":"terms/name/#organize-study-related-files-into-folders-with-consistent-naming-conventions","text":"Organize all your files (whether you will share them or not), into folders. In general, minimize the number of folders at each level, and the number of 'layers' of your whole directory. File naming conventions can often be used quite effectively to 'organize' files and to provide clues as to what the files are and how they relate to each other without resorting to using separation into different directories to serve that purpose. However, there is a limit to naming conventions, and you may want to separate your files into directors based on some type of logical groupings and/or based on th elevel or timing of access to the files you expect to provide. See below for further details. Reminder Before creating more directories or directory layers, consider whether file-naming conventions may be used more efficiently to create this organization.","title":"Organize study-related files into folders with consistent naming conventions"},{"location":"terms/name/#create-logical-groupings","text":"There are a number of ways to group files logically. Below are some examples of how you can logically group your files in folder structures: Grouping strategy Examples By file category Raw data grouped together; processed data grouped together; protocols grouped together; data dictionaries grouped together By experimental subject All raw data files from a particular cell (across all protocols grouped together, etc.) By type of experiment All current clamp experiment files grouped together; all voltage clamp experiment files grouped together By experiment All raw data files mkdocsfrom a particular protocol, across all cells to which the protocol applies, grouped together By file type All CorelDraw figure files grouped together By expected use All files you expect a primary or secondary user of the data/metadata would want to use and/or cite together (as a package) - for example, grouping files that you expect you will want to provide different levels of access to/access restrictions for and/or that you want to provide access to with different timing. See below for more information on access level and timing.","title":"Create logical groupings"},{"location":"terms/name/#consistently-name-your-files-and-folders","text":"","title":"Consistently name your files and folders"},{"location":"terms/name/#universal-conventions","text":"File and folder names should generally be informative/descriptive Wherever possible name your files and folders in a way that will let a human user reasonably infer quite a lot about what the file holds without any further information It is very helpful if file and folder names are all lower case Don't use spaces or special characters Preferred separator is a dash ('-'), e.g., my-data-file-1","title":"Universal conventions"},{"location":"terms/name/#special-conventions","text":"If you have multiple files or folders of the same type , choose a naming convention that's descriptive, and not unmanageably long, and be consistent. For example: One file per day, per cell, per protocol: Potential convention: \"day\"-YYYY-MM-DD-\"cell\"-[0-9]-\"protocol\"-{short-protocol-description} Example filename: day-2023-03-17-cell-3-protocol-200ms-pulse.asc One folder per experimental objective: Potential convention: {cell-type}-{short-experimental-approach-description}-{short-experimental-objective-description} Example foldrer name: drg-current-clamp-effect-of-K1395R-on-drg-neuronal-excitability; drg-voltage-clamp-biophysical-properties-of-K1395R If you have files that are related , choose a naming convention that's descriptive, and not unmanageably long, and be consistent. For example: A tabular/csv data file that has a data dictionary Potential convention: The data dictionary for a data file has the same filename as the data file, with a \"dd-\" prefix Example file name(s): Data file name : my-data-1.csv Corresponding data dictionary file name : dd-my-data-1.csv Several experiments that each have an experimental protocol Potential convention: The protocol of the experiment has the id of that experiment (from the experiment tracker) in the filename, with a \"protocol-\" prefix Example file name(s): Experiment id (from experiment tracker) : exp-1 Corresponding protocol file name : protocol-exp-1.txt","title":"Special conventions"},{"location":"terms/sharing/","text":"Data sharing orientation: Dataset \u00b6 Investigators with this data sharing orientation are interested in sharing their data so that other researchers can get additional value from them and can conduct additional research and analyses beyond what their study investigated. Investigators may want to share as much data as possible from their study, or they may be interested in sharing a specific dataset that they know will have value to others. For example, an investigator may want to share a RNA sequencing data, which is a rich dataset that other investigators could analyze for insights unrelated to the study at hand. Investigators can use any type of annotation with this data sharing orientation. Data sharing orientation: results-support \u00b6 Investigators with this data sharing orientation are interested only in sharing what is necessary to reproduce a specific set of results, generally published in a manuscript. This data sharing orientation may appeal to investigators who have limited or no resources or funding allocated for fulfilling data sharing requirements, as this is the most minimal way to fulfill the HEAL requirements. Investigators may prefer to use minimal annotation with this data sharing orientation.","title":"Data sharing orientations"},{"location":"terms/sharing/#data-sharing-orientation-dataset","text":"Investigators with this data sharing orientation are interested in sharing their data so that other researchers can get additional value from them and can conduct additional research and analyses beyond what their study investigated. Investigators may want to share as much data as possible from their study, or they may be interested in sharing a specific dataset that they know will have value to others. For example, an investigator may want to share a RNA sequencing data, which is a rich dataset that other investigators could analyze for insights unrelated to the study at hand. Investigators can use any type of annotation with this data sharing orientation.","title":"Data sharing orientation: Dataset"},{"location":"terms/sharing/#data-sharing-orientation-results-support","text":"Investigators with this data sharing orientation are interested only in sharing what is necessary to reproduce a specific set of results, generally published in a manuscript. This data sharing orientation may appeal to investigators who have limited or no resources or funding allocated for fulfilling data sharing requirements, as this is the most minimal way to fulfill the HEAL requirements. Investigators may prefer to use minimal annotation with this data sharing orientation.","title":"Data sharing orientation: results-support"},{"location":"terms/studylevel/exp/","text":"About the Experiment Tracker \u00b6 The experiment tracker is an inventory and annotated list of all experiments included in the study. It provides contextual information for each experiment, including research questions, approach, and hypotheses.","title":"Experiment Tracker"},{"location":"terms/studylevel/exp/#about-the-experiment-tracker","text":"The experiment tracker is an inventory and annotated list of all experiments included in the study. It provides contextual information for each experiment, including research questions, approach, and hypotheses.","title":"About the Experiment Tracker"},{"location":"terms/studylevel/resource/","text":"About the Resource Tracker \u00b6 The resource tracker is an inventory and annotated list of all data and supporting/non-data files for the study. Study-Level Metadata \u00b6 Each row of the resource tracker corresponds to one data or non-data resource. Information in the tracker about each resource includes file path, description, access restrictions, format and corresponding software, and dependencies. The resource tracker is where you will also list and annotate any associated results trackers documenting multi-result files. See [LINK: Resource Tracker: Associated Files/Dependencies] for more information on how you should document your dependencies, depending on the type and amount of data you are sharing. For detailed information on the name and definition of each field in the resource tracker, please refer to the [LINK: resource tracker schema]. Associated Data Dictionary \u00b6 This is a field within the resource tracker. Wherever possible, you should document data dictionary files for your study using the associated data dictionary field (assoc.file.dd) rather than in associated files/dependencies. Associated Protocol \u00b6 This is a field within the resource tracker. Wherever possible, you should document protocols for your study using the associated protocol field (assoc.file.protocol) rather than in associated files/dependencies. Associated Results Tracker \u00b6 This is a field within the resource tracker. You should document your results tracker(s) using the associated results tracker field (assoc.file.results.tracker) rather than in associated files/dependencies. Associated Files/Dependencies \u00b6 Any file that the study artefact being annotated depends on to be produced, interpreted, or used (e.g. a processed tabular data file may depend on a raw data file(s), plus a code file that implements the statistical analysis plan to be produced, and require a data dictionary to interpret/use) Note Data dictionaries and protocols should be shared in the more specific Associated data dictionary, Associated protocol fields in the resource tracker wherever possible How you annotate the dependencies of a file in the resource tracker will depend on whether you are annotating wholistically or minimally. If you are annotating artefacts wholistically Use the 'one layer deep' approach : list only the immediate dependencies needed to produce/interpret/use the artefact. List each dependency in the resource tracker in its own row/entry For each row, list dependencies of that file one layer deep Continue until you are annotating files with no dependencies If you are annotating artefacts minimally Use the 'liberal' approach : list all dependencies. For a resource, list immediate dependencies needed to produce/interpret/use the artefact plus dependencies of those dependencies Continue until you are listing files with no dependencies mkdo Example \u00b6 A processed tabular data file may depend on a raw data file(s), plus a code file that implements the statistical analysis plan to be produced, and require a data dictionary to interpret/use. For more information on 'one layer deep' and 'liberal' dependency documentation, click here. 'One layer deep' Dependencies Liberal Dependencies Immediately underlying raw data files, plus a code file that implements the statistical analysis plan and 'transforms' the raw data files into the processed data file, plus the data dictionary for the processed data file All immediate/one layer deep files, AND The statistical analysis plan that was used to produce the code, the data dictionary for the raw underlying data file(s), a protocol for collection of the raw underlying data file(s), etc. If possible, list liberal dependencies in order from most immediate to least immediate.","title":"Resource Tracker"},{"location":"terms/studylevel/resource/#about-the-resource-tracker","text":"The resource tracker is an inventory and annotated list of all data and supporting/non-data files for the study.","title":"About the Resource Tracker"},{"location":"terms/studylevel/resource/#study-level-metadata","text":"Each row of the resource tracker corresponds to one data or non-data resource. Information in the tracker about each resource includes file path, description, access restrictions, format and corresponding software, and dependencies. The resource tracker is where you will also list and annotate any associated results trackers documenting multi-result files. See [LINK: Resource Tracker: Associated Files/Dependencies] for more information on how you should document your dependencies, depending on the type and amount of data you are sharing. For detailed information on the name and definition of each field in the resource tracker, please refer to the [LINK: resource tracker schema].","title":"Study-Level Metadata"},{"location":"terms/studylevel/resource/#associated-data-dictionary","text":"This is a field within the resource tracker. Wherever possible, you should document data dictionary files for your study using the associated data dictionary field (assoc.file.dd) rather than in associated files/dependencies.","title":"Associated Data Dictionary"},{"location":"terms/studylevel/resource/#associated-protocol","text":"This is a field within the resource tracker. Wherever possible, you should document protocols for your study using the associated protocol field (assoc.file.protocol) rather than in associated files/dependencies.","title":"Associated Protocol"},{"location":"terms/studylevel/resource/#associated-results-tracker","text":"This is a field within the resource tracker. You should document your results tracker(s) using the associated results tracker field (assoc.file.results.tracker) rather than in associated files/dependencies.","title":"Associated Results Tracker"},{"location":"terms/studylevel/resource/#associated-filesdependencies","text":"Any file that the study artefact being annotated depends on to be produced, interpreted, or used (e.g. a processed tabular data file may depend on a raw data file(s), plus a code file that implements the statistical analysis plan to be produced, and require a data dictionary to interpret/use) Note Data dictionaries and protocols should be shared in the more specific Associated data dictionary, Associated protocol fields in the resource tracker wherever possible How you annotate the dependencies of a file in the resource tracker will depend on whether you are annotating wholistically or minimally. If you are annotating artefacts wholistically Use the 'one layer deep' approach : list only the immediate dependencies needed to produce/interpret/use the artefact. List each dependency in the resource tracker in its own row/entry For each row, list dependencies of that file one layer deep Continue until you are annotating files with no dependencies If you are annotating artefacts minimally Use the 'liberal' approach : list all dependencies. For a resource, list immediate dependencies needed to produce/interpret/use the artefact plus dependencies of those dependencies Continue until you are listing files with no dependencies mkdo","title":"Associated Files/Dependencies"},{"location":"terms/studylevel/resource/#example","text":"A processed tabular data file may depend on a raw data file(s), plus a code file that implements the statistical analysis plan to be produced, and require a data dictionary to interpret/use. For more information on 'one layer deep' and 'liberal' dependency documentation, click here. 'One layer deep' Dependencies Liberal Dependencies Immediately underlying raw data files, plus a code file that implements the statistical analysis plan and 'transforms' the raw data files into the processed data file, plus the data dictionary for the processed data file All immediate/one layer deep files, AND The statistical analysis plan that was used to produce the code, the data dictionary for the raw underlying data file(s), a protocol for collection of the raw underlying data file(s), etc. If possible, list liberal dependencies in order from most immediate to least immediate.","title":"Example"}]}